### Data

Originally, when we planned to do Russian ASR, we planned to use the OpenSLR Russian LibriSpeech (RuLS) dataset to fine-tune an XLSR-Wav2Vec2 model. 
However, now that we are considering doing End-To-End Speech Translation using Fairseq, we might also use the CoVost dataset, which is 
a multilingual speech-to-text translation corpus from 11 languages into English. We would use the data for Russian speech to English text. This dataset contains 10.2 hours of training data, 9.0 hours of development data, and 8.2 hours of test data.

### Previous Works

In paper [[2] (https://link.springer.com/chapter/10.1007%2F978-3-319-43958-7_13)], Prudnikov et. al. (2016) present the latest improvements to the Russian spontaneous speech recognition system developed in the Speech Technology Center (STC). Spontaneous conversational speech recognition is one of the most difficult tasks in the field of Automatic Speech Recognition, as conversational speech is very noisy and error-prone. Conversational speech varies greatly based on the diversity of individual speakers' speech style, accent, speech rate variability, and the speaker's emotions. It might also contain informal words, such as slang, and might have slurred and poorly articulated words. Background noise and music might also have an effect. There are existing highly effective spontaneous speech recognition systems for English that achieve a WER between 8.0% and 14.1%. In this paper, the goal of the experiment was to build a speaker-independent system for Russian spontaneous speech recognition. This is more challenging for Russian as compared to English for several reasons, two of which are the lack of available datasets, and because Russian is an inflective language with much more unique words than English. The team's previous system achieved a WER of 25.1%, and in this experiment, they improved that rate to 16.4% by using acoustic modelling approaches, combined with deep BLSTM acoustic models and hypothesis rescoring with RNN-based language models. 
